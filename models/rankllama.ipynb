{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8d26c-33f4-40cb-be98-d7923c65fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.cuda.amp import autocast\n",
    "from peft import PeftModel, PeftConfig\n",
    "from tqdm.std import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2fdf6-5caf-4b38-b44c-c26934732049",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55990f2b-ea44-4acb-91c6-a05537c7688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c5e9b-41f7-4e0e-b8f9-678bdfacc55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a000a1-a2fe-4fd4-82ca-358708e8faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_name = \"castorini/rankllama-v1-7b-lora-passage\"\n",
    "data_path = \"../passage_ranking_input_true_data/passage_ranking_query.tsv\"\n",
    "output_path = \"../passage_output_result/rankllama_result.tsv\"\n",
    "batch_size = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59223e-b1df-4369-a34e-2b63acee9784",
   "metadata": {},
   "source": [
    "## loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e50c7c-800e-4e72-9ea7-b52462de9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(data_path,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61ccfb-433f-4303-be8b-ae8e6b126a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc666e28-50d3-4bfc-a135-dbc9afd158d0",
   "metadata": {},
   "source": [
    "## loading model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969dfa2-d050-45f8-a005-5a90f005feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(peft_model_name):\n",
    "    config = PeftConfig.from_pretrained(peft_model_name)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        config.base_model_name_or_path, \n",
    "        device_map={'': 'cuda:0'}, \n",
    "        # device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(base_model, peft_model_name)\n",
    "    model = model.merge_and_unload()\n",
    "    model.eval()\n",
    "    model.to(device) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d078d23-a256-43ef-b00a-6bbcb72171f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "if tokenizer.unk_token is None:\n",
    "    tokenizer.add_special_tokens({'unk_token': '[UNK]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a9609-8142-4312-b32b-881a9bc66518",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843cb03-32d4-43eb-81de-4beca2ae08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95e762-1fe5-4b61-a591-7ca59395471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7aee9-ab48-467b-86f6-1155f94cf912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bacf5-febc-432c-a7bd-db8479833f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(batch_queries, batch_passages):\n",
    "    inputs = tokenizer(\n",
    "        batch_queries,\n",
    "        batch_passages,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            scores = logits.squeeze(-1).cpu().tolist() \n",
    "\n",
    "    del inputs, outputs, logits\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7985b-07f5-4e98-bf30-c9420d7fafe9",
   "metadata": {},
   "source": [
    "## ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1041f0-55af-4a1a-a198-e05149f47a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100\n",
    "scores = []\n",
    "docids = []\n",
    "\n",
    "ranked_docids = []\n",
    "ranked_scores = []\n",
    "\n",
    "batch_queries = []\n",
    "batch_passages = []\n",
    "batch_docids = []\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    query = f'query: {dataset.at[i, \"query\"]}'\n",
    "    passage = f'document: {dataset.at[i, \"passage\"]}'\n",
    "    docid = dataset.at[i, \"pid\"]\n",
    "\n",
    "    batch_queries.append(query)\n",
    "    batch_passages.append(passage)\n",
    "    batch_docids.append(docid)\n",
    "\n",
    "    if len(batch_queries) == batch_size or i == len(dataset) - 1:\n",
    "\n",
    "        batch_scores = get_scores(batch_queries, batch_passages)\n",
    "        scores.extend(batch_scores)\n",
    "        docids.extend(batch_docids)\n",
    "\n",
    "        batch_queries = []\n",
    "        batch_passages = []\n",
    "        batch_docids = []\n",
    "\n",
    "    if len(scores) == chunk_size:\n",
    "        \n",
    "        sorted_scores_docids = sorted(zip(scores, docids), reverse=True, key=lambda x: x[0])\n",
    "        sorted_scores = [score for score, docid in sorted_scores_docids]\n",
    "        sorted_docids = [docid for score, docid in sorted_scores_docids]\n",
    "\n",
    "        ranked_docids.extend(sorted_docids)\n",
    "        ranked_scores.extend(sorted_scores)\n",
    "        scores = []\n",
    "        docids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6a57f-c865-4370-ac0e-2d311ad72deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"ranked_pid\"] = ranked_docids\n",
    "dataset[\"scores\"] = ranked_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9cfcac-a59e-487d-b935-36d60601e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[[\"qid\",\"pid\",\"ranked_pid\",\"scores\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a047a-261f-4465-86e1-47f2473c2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(output_path,sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a96db-da1d-4f96-94e3-304806098acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter-citation",
   "language": "python",
   "name": "my-jupyter-citation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
