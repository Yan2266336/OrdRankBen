{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc6785-0354-4b37-a0d5-582c4732b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm.std import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd59735-42a3-4c8b-a23e-0fb165d3c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ad2a4-3d07-4d8e-9f89-52b8fbe30f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"amberoad/bert-multilingual-passage-reranking-msmarco\"\n",
    "data_path = \"../passage_ranking_input_true_data/passage_ranking_query.tsv\"\n",
    "output_path = '../passage_output_result/bert_multilingual_result.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1bca7-b787-4cf4-ba26-e7b1c1650ed8",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27164ae2-fc0b-4c40-8996-4a1d198e9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(data_path,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d05e89-8c84-47fd-80f7-3ecf05f9d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63519bd1-d827-45ca-a407-b8ad0da7ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda5379-9819-40e6-a235-19ee6232594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362bfcc-51a9-432e-837f-9680230dbb05",
   "metadata": {},
   "source": [
    "## loading model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801e44c-5c18-4671-bcd4-adf77f8dd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bd8da-9366-4ad7-8ee6-da0d2edc1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(query, docs):\n",
    "\n",
    "    if not isinstance(query, str):\n",
    "        query = str(query)\n",
    "    \n",
    "    docs = [str(doc) if not isinstance(doc, str) else doc for doc in docs]\n",
    "    \n",
    "    # Batch encode query and document pairs, ensuring that query is fixed and docs are variable\n",
    "    queries = [query] * len(docs)  # Each document matches the same query.\n",
    "    encoded_inputs = tokenizer.batch_encode_plus(\n",
    "        list(zip(queries, docs)),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return {key: value.to(device) for key, value in encoded_inputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c86957-abf4-41ca-8f83-81ac6cc2e220",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb826299-7c20-4a30-930c-f98d07933dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_batch(query, docs, batch_size=16):\n",
    "    scores = []\n",
    "    # Process documents in batches\n",
    "    for i in range(0, len(docs), batch_size):\n",
    "        # Get the current batch of documents\n",
    "        doc_batch = docs[i:i + batch_size]\n",
    "        \n",
    "        # Batch encode the current batch of documents and queries\n",
    "        inputs = encode_batch(query, doc_batch)\n",
    "        \n",
    "        # inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get the relevance score (select the second logit value to represent the positive class score)\n",
    "        batch_scores = outputs.logits[:, 1].tolist()\n",
    "        scores.extend(batch_scores)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6677cd-4ccb-4427-b68e-c0611f28547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reranking(data, batch_size=16):\n",
    "    reranked_results = {}\n",
    "    for qid in tqdm(data['qid'].unique()):\n",
    "        subset = data[data['qid'] == qid]\n",
    "        query = subset['query'].iloc[0]\n",
    "        # docs = subset['body'].tolist()  # Get all the documents corresponding to the query\n",
    "        docs = subset['passage'].tolist()\n",
    "        pids = subset['pid'].tolist()\n",
    "        \n",
    "        # Reranking documents for each query using batch processing\n",
    "        scores = rerank_batch(query, docs, batch_size=batch_size)\n",
    "        \n",
    "        # Sort documents by score\n",
    "        sorted_docs = sorted(zip(pids, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        ranked_pids = [pid for pid,_ in sorted_docs]\n",
    "        scores_new =  [s for _, s in sorted_docs]\n",
    "        # Store the sorted results\n",
    "        reranked_results[qid] = list(zip(pids, ranked_pids, scores_new))\n",
    "    \n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be853f16-66b5-4686-a13d-44166a7a5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "reranked_results = process_reranking(data_df, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ce953-c79f-4598-b584-58099a9e0c9d",
   "metadata": {},
   "source": [
    "## saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e07b4c-020d-4e39-b37c-6a3352b8daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, 'w') as f:\n",
    "    f.write(\"qid\\tpid\\tranked_pid\\tscores\\n\")\n",
    "    for qid, sorted_docs in reranked_results.items():\n",
    "        for pid, ranked_pid, score in sorted_docs:\n",
    "            # print(doc)\n",
    "            f.write(f\"{qid}\\t{pid}\\t{ranked_pid}\\t{score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4d45f-8848-4785-ad96-3d22a52b3f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter-citation",
   "language": "python",
   "name": "my-jupyter-citation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
