{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c4277-c247-499e-a38c-ad06bc7734a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.std import tqdm\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time  # To add delay between retries if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f900940-d834-4c24-88e5-bfa810819e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'your open AI api key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57dfa59-ca76-4e8c-86a3-fd6e23821c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27f498-f5a3-4e8b-a549-46ccfb0be230",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" ## Instruction: You are an excellent Artificial Intelligence tasked with determining the relevance label between a given query and a passage.\n",
    "\n",
    "## The relevance label should be selected based on the following criteria:\n",
    "    5: 100% Relevant;\n",
    "    4: 75% Relevant;\n",
    "    3: 50% Relevant;\n",
    "    2: 25% Relevant;\n",
    "    1: 0% Relevant. \n",
    "\n",
    "## The input data consists of three components:\n",
    "    query:\n",
    "        The query to evaluate.\n",
    "    passage:\n",
    "        The candidate passage.\n",
    "    binary relevance score:\n",
    "        If 1.0, this means the query and passage are completely relevant. In this case, the relevance label should always be 5.\n",
    "        If 0.0, you need to analyze the semantic relationship and contextual information between the query and the passage to determine the most appropriate relevance label (5, 4, 3, 2, or 1).\n",
    "\n",
    "## Requirement:\n",
    "    When predicting relevance labels, in addition to considering the semantic relevance between the query and the passage, you should also balance the distribution of your predicted labels. This means ensuring that each relevance label (5, 4, 3, 2, 1) is predicted as evenly as possible.\n",
    "\n",
    "## Example 1:\n",
    "    Input:\n",
    "        query: \"How to use Python for data analysis?\"\n",
    "        passage: \"Python is a commonly used programming language for data analysis, data processing, and machine learning.\"\n",
    "        binary relevance score: 1.0\n",
    "    Output:\n",
    "        {\"Relevance Label\": 5}\n",
    "\n",
    "## Example 2:\n",
    "    Input:\n",
    "        query: \"How to optimize website performance?\"\n",
    "        passage: \"Website performance can be optimized by reducing the number of HTTP requests, and optimizing CSS and JavaScript code.\"\n",
    "        binary relevance score: 0.0\n",
    "    Output:\n",
    "        {\"Relevance Label\": 5}\n",
    "## Example 3:\n",
    "    Input:\n",
    "        query: \"What are the benefits of regular exercise?\"  \n",
    "        passage: \"Regular exercise can improve cardiovascular health, enhance mood, and boost energy levels. However, specific routines vary based on individual goals.\"  \n",
    "        binary relevance score: 0.0\n",
    "    Output:\n",
    "        {\"Relevance Label\": 4}\n",
    "\n",
    "## Input Format:\n",
    "    query: <Insert query here>\n",
    "    passage: <Insert passage here>\n",
    "    binary relevance score: <1.0 or 0.0>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c1b80-5c2b-404a-9090-aaf05cdf2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Format:\n",
    "#    {'Relevance Label': <predicted relevance label (5, 4, 3, 2, or 1)>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f0c25-7ac5-4806-8045-e3346516d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(user_prompt):\n",
    "    \n",
    "    completion = Client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        # model=\"gpt-4o-mini-2024-07-18\",\n",
    "        response_format={ \n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\":\"Relevance\",\n",
    "                \"strict\":True,\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"Relevance Label\": {\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"Relevance Label\"],\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2742de-bf53-4989-9c78-bafc8dcb13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(query, passage, rel_score):\n",
    "    return f\"query: {query} \\n\" \\\n",
    "           f\"passage: {passage} \\n\" \\\n",
    "           f\"binary relevance score: {rel_score}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a2710-649b-4ec3-9ed5-efc48809c62f",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45bd049-135f-4b97-8069-fc4104e31f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"document/filtered_passage_reranking_data.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30406d-da02-4ee9-b4ef-cd90cbdd71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e1985-6572-4cc5-b68c-94c31fb95d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.qid == 20432].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f0289-7137-4d8c-9eff-e280ae93a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "Index = 6501  # Initial Index=1\n",
    "# Start index = (Index-1)*batch_size\n",
    "\n",
    "for i in range(650000, len(data), batch_size):\n",
    "    relevance_label = []\n",
    "    new_data = data[i:i+batch_size]\n",
    "    for row in tqdm(new_data.itertuples()):\n",
    "        query = row.query\n",
    "        passage = row.passage\n",
    "        rel_score = row.relevance_score\n",
    "\n",
    "        user_prompt = get_user_prompt(query, passage, rel_score)\n",
    "\n",
    "        while True:  # Retry loop for error handling\n",
    "            try:\n",
    "                response = get_response(user_prompt)\n",
    "                label = json.loads(response).get(\"Relevance Label\")\n",
    "                relevance_label.append(int(label))\n",
    "                break  # Exit loop if successful\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"JSON decoding error. Re-generating response...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}. Re-generating response...\")\n",
    "\n",
    "            # Optionally add a delay to avoid overwhelming external systems\n",
    "            time.sleep(0.5)  \n",
    "            user_prompt = get_user_prompt(query, passage, rel_score)\n",
    "\n",
    "    new_data[\"relevance_score\"] = relevance_label\n",
    "    new_data.to_csv(f\"document/temp/temp_passage_ranking_{Index}.tsv\", sep=\"\\t\", index=False)\n",
    "    Index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c4ed2-c011-4435-977e-1bfd5afb94b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter-citation",
   "language": "python",
   "name": "my-jupyter-citation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
